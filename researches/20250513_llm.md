# From Millions of Tweets to Actionable Insights: Leveraging LLMs for User Profiling
## Summary: 

ソーシャルメディアユーザープロファイリングはコンテンツ分析を通じて、誤情報検出、エンゲージメント予測、ヘイトスピーチモニタリング、ユーザー行動モデリングなどのタスクに不可欠です。しかし、ツイート要約、属性ベースのプロファイリング、潜在表現学習などの既存のプロファイリング技術には、転用可能性の欠如、解釈不可能な特徴の生成、大規模なラベル付きデータセットの必要性、適応性を制限する固定の事前定義カテゴリへの依存など、重大な制限があります。私たちは、ドメイン定義ステートメントを活用する新しい大規模言語モデル（LLM）ベースのアプローチを導入します。これらは、プロファイリングの基盤として、ドメインの重要な柱を概説する主要な特性として機能します。私たちの二段階メソッドは、最初にドメイン固有の知識ベースを用いた半教師あり型フィルタリングを採用し、その後、抽象的（合成された説明）と抽出的（代表的なツイート選択）の両方のユーザープロファイルを生成します。最小限の人間による検証でLLMの固有知識を活用することで、私たちのアプローチは大規模なラベル付きデータセットの必要性を減らしながら、ドメイン間で適応可能です。私たちの方法は解釈可能な自然言語ユーザープロファイルを生成し、広範なユーザーデータを凝縮して、下流のソーシャルネットワークタスクのためにLLMの推論と知識能力を解き放つスケールにします。私たちはペルシャ語の政治的Twitter（X）データセットと人間の検証を伴うLLMベースの評価フレームワークを提供します。実験結果は、私たちの方法が柔軟で適応可能、かつ解釈可能なユーザープロファイルを作成する効果を示し、最先端のLLMベースおよび従来の方法を9.8％上回ることを示しています。
## Authors: 
- Vahid Rahimzadeh
- Ali Hamzehpour
- Azadeh Shakery
- Masoud Asadpour

## Published Date:
 2025-05-09 16:51:24+00:00
## URL

 abs: http://arxiv.org/abs/2505.06184v1

pdf: http://arxiv.org/pdf/2505.06184v1
# A Large Language Model-Enhanced Q-learning for Capacitated Vehicle Routing Problem with Time Windows
## Summary: 

時間枠付き容量制約付き車両経路問題（CVRPTW）は、物流配送と輸送管理に広く適用されるクラシックなNP困難な組合せ最適化問題です。その複雑さは車両容量と時間枠の制約に由来し、従来のアプローチに大きな課題をもたらします。大規模言語モデル（LLM）の進歩により、CVRPTWの近似解を見つけるための新たな可能性が提供されています。本論文では、リアルタイム緊急制約を持つCVRPTWに対処するための新しいLLM強化Q学習フレームワークを提案します。私たちの解決策は、LLMガイド型探索フェーズからQネットワークの自律最適化フェーズへの移行を行う適応型二段階トレーニングメカニズムを導入しています。信頼性を確保するために、Chain-of-Thought（CoT）に基づくLLMのための三層自己修正メカニズムを設計しました：構文検証、意味検証、物理的制約の強制です。さらに、アーキテクチャにおけるLLMの規制役割を増幅するために、LLMによって生成された経験の優先リプレイも行いました。実験結果は、私たちのフレームワークが従来のQ学習と比較して平均7.3％のコスト削減を達成し、収束に必要なトレーニングステップも少なくて済むことを示しています。
## Authors: 
- Linjiang Cao
- Maonan Wang
- Xi Xiong

## Published Date:
 2025-05-09 16:45:43+00:00
## URL

 abs: http://arxiv.org/abs/2505.06178v1

pdf: http://arxiv.org/pdf/2505.06178v1
# MonetGPT: Solving Puzzles Enhances MLLMs' Image Retouching Skills
## Summary: 

レタッチは生写真のポスト操作において不可欠なタスクです。テキストやストロークによるジェネレーティブ編集は、ユーザーがアクセスできる新しいツールを提供しますが、元のオブジェクトのアイデンティティを容易に受け入れがたく予測不可能な方法で変更してしまう可能性があります。対照的に、従来の手続き的編集（Gimp、Lightroomなどのフォトエディットツールで一般的にサポートされている）は保守的ですが、プロフェッショナルによってまだ好まれています。残念ながら、プロフェッショナル品質のレタッチには多くの個別の手続き的編集操作が含まれ、ほとんどの初心者にとって計画するのが難しいです。本論文では、マルチモーダル大規模言語モデル（MLLM）が生写真を批評し、適切な改善策を提案し、最終的に与えられた事前に作成された手続き的画像操作セットでそれらを実現することを学べるかどうかを問います。我々は、MLLMが特別に設計された視覚パズルを解くことによって、まず基礎となる画像処理操作を認識できるようになることを実証します。その後、そのような操作を認識したMLLMは編集シーケンスを計画し提案することができます。トレーニングを容易にするために、専門家が編集した写真のセットを与えられると、専門家の編集を手続き的に操作し、次に視覚的調整に基づいて事前訓練されたLLMを根拠付けて、微調整のための推論を合成します。提案されたレタッチ操作は、構成上、ユーザーが理解でき、オブジェクトの詳細と解像度を保存し、オプションでオーバーライドすることができます。我々はさまざまなテスト例で私たちのセットアップを評価し、説明可能性とアイデンティティ保存の観点から、既存のジェネレーティブおよび他の手続き的な代替手段に比べて利点を示します。コード、データ、モデル、および補足結果は、私たちのプロジェクトウェブサイト https://monetgpt.github.io/ で見つけることができます。
## Authors: 
- Niladri Shekhar Dutt
- Duygu Ceylan
- Niloy J. Mitra

## Published Date:
 2025-05-09 16:38:27+00:00
## URL

 abs: http://arxiv.org/abs/2505.06176v1

pdf: http://arxiv.org/pdf/2505.06176v1
# Turbo-ICL: In-Context Learning-Based Turbo Equalization
## Summary: 

本論文は、大規模言語モデル（LLM）にインスパイアされた、符号化された多入力多出力（MIMO）システムにおけるソフト入力ソフト出力チャネル等化のための新しい文脈内学習（ICL）フレームワークを紹介します。提案されたアプローチは、パイロット信号とデコーダフィードバックのプロンプトから直接、後続のシンボル分布を推論することを学習します。重要な革新点は、デコーダ出力からの外部情報を追加の文脈として含めるためのプロンプト拡張の使用であり、これによりICLモデルはターボ復号反復を通じてシンボル推定を反復的に改善することができます。トランスフォーマーベースと状態空間アーキテクチャに基づく2つのモデルバリアントが開発され、評価されています。広範なシミュレーションは、低解像度量子化の存在など、従来の線形仮定が破綻する場合、ICL等化器が一貫して従来のモデルベースのベースラインを上回ることを示しており、後者が完全なチャネル状態情報を提供されている場合でもそうです。結果はまた、限られたトレーニング多様性下でのトランスフォーマーベースのモデルの優位性と、リソース制約のあるシナリオでの状態空間モデルの効率性も強調しています。
## Authors: 
- Zihang Song
- Matteo Zecchin
- Bipin Rajendran
- Osvaldo Simeone

## Published Date:
 2025-05-09 16:29:29+00:00
## URL

 abs: http://arxiv.org/abs/2505.06175v1

pdf: http://arxiv.org/pdf/2505.06175v1
# A Scaling Law for Token Efficiency in LLM Fine-Tuning Under Fixed Compute Budgets
## Summary: 

固定計算予算下での大規模言語モデル（LLM）の微調整におけるデータ構成を明示的に考慮したスケーリング法則を導入します。従来のアプローチではトレーニングデータを総トークン数のみで測定していますが、例の数とその平均トークン長—我々が「データセットボリューム」と呼ぶもの—がモデルのパフォーマンスに決定的な役割を果たします。我々の定式化は確立された手順に従って調整されています。BRICC データセット\cite{salavati2024reducing}とMMMLU データセット\cite{hendrycks2021measuringmassivemultitasklanguage}のサブセットに関する実験は、複数のサブサンプリング戦略の下で評価され、データ構成がトークン効率に著しく影響を与えることを明らかにしています。これらの結果は、リソースが制約された環境での実用的なLLM微調整のための改良されたスケーリング法則を動機付けています。
## Authors: 
- Ryan Lagasse
- Aidan Kiernans
- Avijit Ghosh
- Shiri Dori-Hacohen

## Published Date:
 2025-05-09 16:02:23+00:00
## URL

 abs: http://arxiv.org/abs/2505.06150v1

pdf: http://arxiv.org/pdf/2505.06150v1
# Can Prompting LLMs Unlock Hate Speech Detection across Languages? A Zero-shot and Few-shot Study
## Summary: 

自動化されたヘイトスピーチ検出への関心の高まりにもかかわらず、既存のアプローチのほとんどはオンラインコンテンツの言語的多様性を見過ごしています。LLaMA、Aya、Qwen、BloomZなどの多言語指示調整された大規模言語モデルは、言語間で有望な能力を提供しますが、ゼロショットおよび少数ショットプロンプティングを通じてヘイトスピーチを特定する効果はまだ十分に探求されていません。この研究では、8つの非英語言語にわたるLLMプロンプティングベースの検出を評価し、いくつかのプロンプティング技術を活用し、それらを微調整されたエンコーダモデルと比較します。ゼロショットおよび少数ショットプロンプティングは、ほとんどの実世界の評価セットで微調整されたエンコーダモデルに遅れをとっていますが、ヘイトスピーチ検出の機能テストではより良い一般化を達成することを示しています。また、研究ではプロンプト設計が重要な役割を果たし、各言語がパフォーマンスを最大化するためにしばしばカスタマイズされたプロンプティング技術を必要とすることも明らかになっています。
## Authors: 
- Faeze Ghorbanpour
- Daryna Dementieva
- Alexander Fraser

## Published Date:
 2025-05-09 16:00:01+00:00
## URL

 abs: http://arxiv.org/abs/2505.06149v1

pdf: http://arxiv.org/pdf/2505.06149v1
# ELA-ZSON: Efficient Layout-Aware Zero-Shot Object Navigation Agent with Hierarchical Planning
## Summary: 

複雑な複数の部屋を持つ屋内環境向けに設計された、効率的なレイアウト認識型ゼロショットオブジェクトナビゲーション（ZSON）アプローチであるELA-ZSONを紹介します。
  レイアウト情報を含むグローバルトポロジカルマップと詳細なシーン表現メモリを持つローカル命令的アプローチを活用した階層的計画により、ELA-ZSONは効率的かつ効果的なナビゲーションを実現します。
  このプロセスはLLM駆動のエージェントによって管理され、人間の相互作用、複雑な報酬、または高価なトレーニングを必要とせずに、シームレスで効果的な計画とナビゲーションを保証します。
  MP3Dベンチマークでの実験結果は、85％のオブジェクトナビゲーション成功率（SR）と79％のパス長で重み付けされた成功率（SPL）を達成しています（既存の方法と比較してSRで40％以上のポイント改善とSPLで60％の改善）。さらに、仮想エージェントと実世界のロボット展開を通じて、実用的なシナリオでの能力を示すことで、私たちのアプローチの堅牢性を検証しています。詳細については https://anonymous.4open.science/r/ELA-ZSON-C67E/ をご覧ください。
## Authors: 
- Jiawei Hou
- Yuting Xiao
- Xiangyang Xue
- Taiping Zeng

## Published Date:
 2025-05-09 15:39:37+00:00
## URL

 abs: http://arxiv.org/abs/2505.06131v1

pdf: http://arxiv.org/pdf/2505.06131v1
# LLMs Get Lost In Multi-Turn Conversation
## Summary: 

大規模言語モデル（LLM）は会話インターフェースです。そのため、LLMはユーザーがタスクを完全に指定できる場合だけでなく、マルチターン会話のやり取りを通じて必要なものを定義、探索、洗練するのを支援する可能性があります。LLM会話ログの分析により、ユーザーの指示に不完全な仕様が頻繁に発生することが確認されていますが、LLM評価は主に単一ターンの完全に指定された指示設定に焦点を当ててきました。この研究では、単一ターンとマルチターン設定でのLLMパフォーマンスを比較する大規模シミュレーション実験を実施します。私たちの実験により、テストしたすべてのトップオープン＆クローズド重みLLMが、シングルターンよりもマルチターン会話で著しく低いパフォーマンスを示すことが確認されました。6つの生成タスク全体で平均39％の低下が見られます。200,000以上のシミュレーション会話の分析により、パフォーマンス低下は二つの要素に分解されます：適性の軽微な損失と信頼性の著しい低下です。LLMは初期のターンで仮定を行い、早期に最終解決策の生成を試み、それに過度に依存することがわかりました。より簡単に言えば、*LLMが会話で間違ったターンをとると、迷子になり回復しない*ことを発見しました。
## Authors: 
- Philippe Laban
- Hiroaki Hayashi
- Yingbo Zhou
- Jennifer Neville

## Published Date:
 2025-05-09 15:21:44+00:00
## URL

 abs: http://arxiv.org/abs/2505.06120v1

pdf: http://arxiv.org/pdf/2505.06120v1
# LLMs Outperform Experts on Challenging Biology Benchmarks
## Summary: 

この研究は、分子生物学、遺伝学、クローニング、ウイルス学、およびバイオセキュリティにまたがる8つの多様な生物学ベンチマークにおいて、27の最先端大規模言語モデルを体系的に評価しています。2022年11月から2025年4月の間に主要なAI開発者からリリースされたモデルが、ベンチマークごとに10回の独立した実行を通じて評価されました。調査結果は、生物学的能力の劇的な向上を明らかにしています。最高モデルのパフォーマンスは、研究期間中に難易度の高いウイルス学能力テストのテキストのみのサブセットで4倍以上増加し、最高モデルは現在、専門ウイルス学者より2倍優れたパフォーマンスを示しています。いくつかのモデルは、LAB-Bench CloningシナリオやGPQAとWMDPの生物学サブセットなど、他の難しいベンチマークでも専門家レベルのパフォーマンスに達しているか、それを超えています。予想に反して、思考の連鎖はゼロショット評価よりも実質的にパフォーマンスを向上させず、o3-miniとClaude 3.7 Sonnetの拡張推論機能は通常、推論スケーリングによって予測されるようにパフォーマンスを向上させました。PubMedQAやMMLUとWMDPの生物学サブセットなどのベンチマークは、100％を大幅に下回るパフォーマンスの停滞を示し、ベンチマークの飽和と基礎となるベンチマークデータのエラーを示唆しています。分析は、AIシステムが進化し続けるにつれて、より洗練された評価方法の必要性を強調しています。
## Authors: 
- Lennart Justen

## Published Date:
 2025-05-09 15:05:57+00:00
## URL

 abs: http://arxiv.org/abs/2505.06108v1

pdf: http://arxiv.org/pdf/2505.06108v1
# Free and Fair Hardware: A Pathway to Copyright Infringement-Free Verilog Generation using LLMs
## Summary: 

機能的なVerilogコードの生成などのハードウェア設計タスクにおける大規模言語モデル（LLM）の能力の限界により、オープンソースリポジトリからキュレーションされたハードウェアデータセットを利用した様々な微調整最適化が動機付けられてきました。しかし、これらのデータセットはサイズが限られており、再利用のためのライセンスに関する最小限のチェックしか含まれていないため、微調整されたLLMによる潜在的な著作権侵害が発生する可能性があります。そこで、Verilogトレーニング済みLLMが著作権保護されたコードを生成するリスクを推定するための評価ベンチマークを提案します。このリスクを最小化するために、22万以上のファイルを含むオープンソースVerilogデータセット、FreeSetと、公正使用Verilogデータの追加保証を提供するために使用された自動データセットキュレーションフレームワークを提示します。その後、継続的な事前トレーニングからなるLLM微調整フレームワークを実行し、Verilog用に微調整されたLlamaモデル、FreeVを作成します。我々の結果は、FreeVが3%の違反率のみで、以前の研究の中で著作権侵害のリスクが最も低いことを示しています。さらに、実験結果はベースラインモデルに対するVerilog生成機能の改善を示し、VerilogEvalのpass@10率を10%以上向上させています。
## Authors: 
- Sam Bush
- Matthew DeLorenzo
- Phat Tieu
- Jeyavijayan Rajendran

## Published Date:
 2025-05-09 14:44:07+00:00
## URL

 abs: http://arxiv.org/abs/2505.06096v1

pdf: http://arxiv.org/pdf/2505.06096v1
